Redis 就直接看《Redis 设计与实现》好了，这本书真的是通俗易懂，读起来几乎没什么障碍，小白的话应该也可以直接上手

# redis介绍

**redis**：用于缓存、发布订阅、高速队列，  select 16 ，

基本数据类型：string、list、hash、set、zset ，

三种特殊数据类型：bitmap（0、1），geo，hyprologlog（基数，在误差可接受范围内快速计算基数）

redis支持事务：multe，命令入队，exec ， redis事务没有原子性

### Redis单机模式

优点：

1. 架构简单，部署方便。
2. 高性价比：缓存使用时无需备用节点(单实例可用性可以用 supervisor 或 crontab 保证)，当然为了满足业务的高可用性，也可以牺牲一个备用节点，但同时刻只有一个实例对外提供服务。
3. 高性能。

确定：

1. 不保证数据的可靠性。
2. 在缓存使用，进程重启后，数据丢失，即使有备用的节点解决高可用性，但是仍然不能解决缓存预热问题，因此不适用于数据可靠性要求高的业务。
3. 高性能受限于单核 CPU 的处理能力(Redis 是单线程机制)，CPU 为主要瓶颈，所以适合操作命令简单，排序、计算较少的场景。也可以考虑用 Memcached 替代。

### 主从模式

Redis 采用主从(可以多从)部署结构，相较于单副本而言最大的特点就是主从实例间数据实时同步，并且提供数据持久化和备份策略。主从实例部署在不同的物理服务器上，根据公司的基础环境配置，可以实现同时对外提供服务和读写分离策略。

**优点：**

1. 高可靠性：一方面，采用双机主备架构，能够在主库出现故障时自动进行主备切换，从库提升为主库提供服务，保证服务平稳运行;另一方面，开启数据持久化功能和配置合理的备份策略，能有效的解决数据误操作和数据异常丢失的问题。
2. 读写分离策略：从节点可以扩展主库节点的读能力，有效应对大并发量的读操作。

**缺点：**

1. 故障恢复复杂，如果没有 RedisHA 系统(需要开发)，当主库节点出现故障时，需要手动将一个从节点晋升为主节点，同时需要通知业务方变更配置，并且需要让其它从库节点去复制新主库节点，整个过程需要人为干预，比较繁琐。
2. 主库的写能力受到单机的限制，可以考虑分片。
3. 主库的存储能力受到单机的限制，可以考虑 Pika。
4. 原生复制的弊端在早期的版本中也会比较突出，如：Redis 复制中断后，Slave 会发起 psync，此时如果同步不成功，则会进行全量同步，主库执行全量备份的同时可能会造成毫秒或秒级的卡顿;又由于 COW 机制，导致极端情况下的主库内存溢出，程序异常退出或宕机;主库节点生成备份文件导致服务器磁盘 IO 和 CPU(压缩)资源消耗;发送数 GB 大小的备份文件导致服务器出口带宽暴增，阻塞请求，建议升级到最新版本。

### 哨兵模式

主从模式的升级， 手动到自动的升级，

**优点：**

1. Redis Sentinel 集群部署简单。
2. 能够解决 Redis 主从模式下的高可用切换问题。
3. 很方便实现 Redis 数据节点的线形扩展，轻松突破 Redis 自身单线程瓶颈，可极大满足 Redis 大容量或高性能的业务需求。
4. 可以实现一套 Sentinel 监控一组 Redis 数据节点或多组数据节点。

**缺点： 扩容麻烦， 配置麻烦**

1. 部署相对 Redis 主从模式要复杂一些，原理理解更繁琐。
2. 资源浪费，Redis 数据节点中 slave 节点作为备份节点不提供服务。
3. Redis Sentinel 主要是针对 Redis 数据节点中的主节点的高可用切换，对 Redis 的数据节点做失败判定分为主观下线和客观下线两种，对于 Redis 的从节点有对节点做主观下线操作，并不执行故障转移。
4. 不能解决读写分离问题，实现起来相对复杂。

### 集群模式

Redis Cluster 是 3.0 版后推出的 Redis 分布式集群解决方案，主要解决 Redis 分布式方面的需求，比如，当遇到单机内存，并发和流量等瓶颈的时候，Redis Cluster 能起到很好的负载均衡的目的。Redis Cluster 集群节点最小配置 6 个节点以上(3 主 3 从)，其中主节点提供读写操作，从节点作为备用节点，不提供请求，只作为故障转移使用。Redis Cluster 采用虚拟槽分区，所有的键根据哈希函数映射到 0～16383 个整数槽内，每个节点负责维护一部分槽以及槽所印映射的键值数据。

**优点：**

1. 无中心架构。
2. 数据按照 slot 存储分布在多个节点，节点间数据共享，可动态调整数据分布。
3. 可扩展性：可线性扩展到 1000 多个节点，节点可动态添加或删除。
4. 高可用性：部分节点不可用时，集群仍可用。通过增加 Slave 做 standby 数据副本，能够实现故障自动 failover，节点之间通过 gossip 协议交换状态信息，用投票机制完成 Slave 到 Master 的角色提升。
5. 降低运维成本，提高系统的扩展性和可用性。

**缺点：**

1. Client 实现复杂，驱动要求实现 Smart Client，缓存 slots mapping 信息并及时更新，提高了开发难度，客户端的不成熟影响业务的稳定性。目前仅 JedisCluster 相对成熟，异常处理部分还不完善，比如常见的“max redirect exception”。
2. 节点会因为某些原因发生阻塞(阻塞时间大于 clutser-node-timeout)，被判断下线，这种 failover 是没有必要的。
3. 数据通过异步复制，不保证数据的强一致性。
4. 多个业务使用同一套集群时，无法根据统计区分冷热数据，资源隔离性较差，容易出现相互影响的情况。
5. Slave 在集群中充当“冷备”，不能缓解读压力，当然可以通过 SDK 的合理设计来提高 Slave 资源的利用率。
6. Key 批量操作限制，如使用 mset、mget 目前只支持具有相同 slot 值的 Key 执行批量操作。对于映射为不同 slot 值的 Key 由于 Keys 不支持跨 slot 查询，所以执行 mset、mget、sunion 等操作支持不友好。
7. Key 事务操作支持有限，只支持多 key 在同一节点上的事务操作，当多个 Key 分布于不同的节点上时无法使用事务功能。
8. Key 作为数据分区的最小粒度，不能将一个很大的键值对象如 hash、list 等映射到不同的节点。
9. 不支持多数据库空间，单机下的 redis 可以支持到 16 个数据库，集群模式下只能使用 1 个数据库空间，即 db 0。
10. 复制结构只支持一层，从节点只能复制主节点，不支持嵌套树状复制结构。
11. 避免产生 hot-key，导致主库节点成为系统的短板。
12. 避免产生 big-key，导致网卡撑爆、慢查询等。
13. 重试时间应该大于 cluster-node-time 时间。
14. Redis Cluster 不建议使用 pipeline 和 multi-keys 操作，减少 max redirect 产生的场景。

### 第三方模式codis

codis

Codis最大的优势在于支持平滑增加（减少）Redis Server Group（Redis实例），能安全、透明地迁移数据，这也是Codis 有别于Twemproxy等静态分布式 Redis 解决方案的地方。

## 应用场景⭐

1. 缓存
2. 共享Session
3. 消息队列系统，通知
4. 分布式锁

------

# 常问面试题

## Redis持久化RDB快照& AOF日志/秒⭐

- RDB：快照形式是直接把内存中的数据保存到一个dump的文件中，定时保存，保存策略。 当Redis需要做持久化时，Redis会fork一个子进程，子进程将数据写到磁盘上一个临时RDB文件中。当子进程完成写临时文件后，将原来的RDB替换掉。
- AOF：把所有的对Redis的服务器进行修改的命令都存到一个文件里，命令的集合。 使用AOF做持久化，每一个写命令都通过write函数追加到appendonly.aof中。aof的默认策略是每秒钟fsync一次，在这种配置下，就算发生故障停机，也最多丢失一秒钟的数据。 缺点是对于相同的数据集来说，AOF的文件体积通常要大于RDB文件的体积。根据所使用的fsync策略，AOF的速度可能会慢于RDB。对于主从同步来说，主从刚刚连接的时候，进行全量同步（RDB）；全同步结束后，进行增量同步(AOF)。

如果同时使用 RDB 和 AOF 两种持久化机制，那么在 redis 重启的时候，会使用 **AOF** 来重新构建数据，因为 AOF 中的**数据更加完整**。

### RDB & AOF优缺点

**RDB 持久化优点**

- RDB是一个紧凑压缩的二进制文件，存储效率高， RDB恢复数据速度比AOF快

**RDB持久化缺点**

- 无法做到实时持久化，具有较大可能丢失数据
- 存储数量较大时，效率较低，I／O性能较低
- 基于fork创建子进程，内存产生额外消耗
- 宕机带来的数据丢失风险

**AOF 优点**

- AOF 可以更好的保护 数据不丢失，一般 AOF 会每隔 1 秒，最多丢失 1 秒钟的数据。
- 写入性能非常高，而且文件不容易破损
- **适合做灾难性的误删除的紧急恢复**。

**AOF 缺点**

- 对于同一份数据来说，AOF 日志文件通常比 RDB 数据快照文件更大。  恢复速度较慢

#### RDB 与 AOF 如何选择

**AOF：**对数据非常敏感，建议使用默认的AOF持久化方案
AOF策略使用everysec，每秒fsync一次，该策略仍可保持很好性能，出现问题最多丢失一秒内的数据
**RDB：**数据可以做到阶段内无丢失，且恢复较快，阶段点数据恢复通常使用RDB方案

**综合：**

如果不能承受分钟内的数据丢失，对业务数据非常敏感，选用AOF
如果能承受分钟内的数据丢失，且追求大数据集的恢复速度选用RDB，RDB 非常适合灾难恢复。
双保险策略，同时开启RDB和AOF，重启后Redis优先使用AOF来恢复数据，降低丢失数据量

------

## [Redis缓存雪崩、击穿、穿透、双写一致性、并发竞争、热点key重建优化、BigKey的优化 等解决方案](https://www.cnblogs.com/yaopengfei/p/13878124.html)

### 一. 缓存雪崩

**含义：在一个较短的时间内，缓存中较多的key集中过期或者缓存挂了**，导致了**数据库服务器崩溃**

**缓存雪崩的事前事中事后的解决方案如下：**

(1). 设置不同的缓存失效时间，比如可以在缓存过期时间后面加个随机数，这样就避免同一时刻缓存大量过期失效。

setRedis（key，value，time + Math.random() * 9999）；

(2). 针对系统的一些热点数据， 可以设置缓存永不过期。 （或者定时更新）

(3). 设置二级缓存架构C1、C2，C1在前，C2在后，C1的缓存可以设置不同的过期时间，C2缓存与DB保持强一致性，实现数据同步。

**PS：该二级缓存架构，同样也适用于解决下面的缓存击穿。**

(4). 从架构层面来说：Redis做集群，将热点数据分配在不同的master上，减轻单点压力，同时master要对应多个slave，保证高可用；  系统架构要有快速熔断策略，减轻系统的压力。

### 二. 缓存穿透

**含义：**业务请求中数据缓存中没有，DB中也没有，导致类似请求直接跨过缓存，反复在DB中查询，与此同时缓存也**不会**得到更新。

**原因：**

1. Redis中大面积出现未命中
2. 出现非正常URL访问

**解决方案：**

(1). cache null策略：DB查询的结果即使为null，也给缓存的value设置为null，同时可以设置一个较短的过期时间，这样就避免不存在的数据跨过缓存直接打到DB上。

最简单粗暴的方法如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们就把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。

(2). 布隆过滤器：

事先把存在的key都放到redis的**BloomFilter** 过滤器中，他的用途就是存在性检测，如果 BloomFilter 中不存在，那么数据一定不存在；如果 BloomFilter 中存在，实际数据也有可能会不存在。

**布隆过滤器（Bloom Filter）**这个也能很好的预防缓存穿透的发生，就是利用高效的数据结构和算法快速判断出你这个Key是否在数据库中存在，不存在你return就好了，存在你就去查DB刷新KV再return

### 三.缓存击穿

某热点Key扛着大量的并发请求，当key失效的一瞬间，大量的QPS打到DB上，导致系统瘫痪。

解决：

(1). 热点key过期时间后加随机数 。

(2). 热点key缓存永不过期（但是value需要开个子线程去更新）

(3). 二级缓存架构策略。

设置二级缓存架构C1、C2，C1在前，C2在后，C1的缓存可以设置不同的过期时间，C2缓存与DB保持强一致性，实现数据同步。

(4). 采用互斥锁更新，保证同一进程针对相同的数据不会并发打到DB上，从而减轻DB的压力。

(5). 缓存失效的时候随机sleep一个很短的时间，再次查询，如果失败则执行更新操作。

**假如 Redis  里面有 1  亿个 key ，其中有 10w 个 个 key  是以某个固定的已知的前缀开头的，如**
**果将它们全部找出来？**
使用 keys 指令可以扫出指定模式的 key 列表。
对方接着追问：如果这个 redis 正在给线上的业务提供服务，那使用 keys 指令会有什么问题？
这个时候你要回答 redis 关键的一个特性：redis 的单线程的。keys 指令会导致线程阻塞一
段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用 scan 指
令，scan 指令可以无阻塞的提取出指定模式的 key 列表，但是会有一定的重复概率，在客
户端做一次去重就可以了，但是整体所花费的时间会比直接用 keys 指令长。

### 四. 双写一致性

**含义**

双写一致性的含义就是：保证缓存中的数据 和 DB中数据一致。

**单线程下的解决方案**

单线程下实际上就是指并发不大，或者说对 缓存和DB数据一致性要求不是很高的情况。

该问题就是经典的：缓存+数据库读写的模式，就是 **Cache Aside Pattern**

解决思路：

(1). 查询的时候，先查缓存，缓存中有数据，直接返回；缓存中没有数据，去查询数据库，然后更新缓存。

(2). 更新DB的后，删除缓存。

**剖析：**

(1). 为什么更新DB后，是删除缓存，而不是更新缓存呢？

举个例子，比如该DB更新的频率很高，比如1min中内更新100次把，如果更新缓存，缓存也对应了更新了100次，但缓存在这一分钟内根本没被调用，或者说该缓存10min才可能会被查询一次，那么频繁更新缓存是不是就产生了很多不必要的开销呢。

所以我们这里的思路是：**用到缓存的时候，才去计算缓存**。

(2). 该方案高并发场景下是否适用？

不适用

比如更新DB后，还有没有来得及删除缓存，别的请求就已经读取到缓存的数据了，此时读取的数据和DB中的实际的数据是不一致的。



**高并发下的解决方案**

使用内存队列解决，把 读请求 和 写请求 都放到队列中，按顺序执行（即串行化的方式解决）。（要定义多个队列，不同的商品放到不同的队列中，换言之，同一个队列中只有一类商品）

**剖析：**

这种方案也有弊端，当并发量高了，队列容易阻塞，这个队列的位置，反而成了整个系统的瓶颈了，所以说100%完美的方案不存在，只有最适合的方案，没有最完美的方案。

![img](https://cdn.nlark.com/yuque/0/2021/png/2923566/1637772085961-de71d5e8-ec52-4bbd-a8bf-2c06a9a9237b.png)

### 五. 并发竞争

1. 含义

多个微服务系统要同时操作redis的同一个key，比如正确的顺序是 A→B→C，A执行的时候，突然网络抖动了一下，导致B，C先执行了，从而导致整个流程业务错误。

1. 解决方案

引入分布式锁(zookeeper 或 redis自身)

每个系统在操作之前，都要先通过 Zookeeper 获取分布式锁，确保同一时间，只能有一个系统实例在操作这个个 Key，别系统都不允许读和写。



### 六. 热点缓存key的重建优化

**1. 背景**

开发人员使用“缓存+过期时间”的策略既可以加速数据读写， 又保证数据的定期更新， 这种模式基本能够满足绝大部分需求。 但是有两个问题如果同时出现， 可能就会对应用造成致命的危害：

(1). 当前key是一个热点key（例如一个热门的娱乐新闻），并发量非常大。

(2). 重建缓存不能在短时间完成， 可能是一个复杂计算， 例如复杂的SQL、 多次IO、 多个依赖等。

在**缓存失效的瞬间**， 有**大量线程来重建缓存， 造成后端负载加大**， 甚至可能会让应用崩溃。

**2. 解决方案**

要解决这个问题主要就是要**避免大量线程同时重建缓存**。

我们可以利用**互斥锁**来解决，此方法**只允许一个线程重建缓存**， 其他线程等待重建缓存的线程执行完， 重新从缓存获取数据即可。

```java
String get(String key) {
 // 从Redis中获取数据
 String value = redis.get(key);
 // 如果value为空， 则开始重构缓存
 if (value == null) {
  // 只允许一个线程重建缓存， 使用nx， 并设置过期时间ex
  String mutexKey = "mutext:key:" + key;
  if (redis.set(mutexKey, "1", "ex 180", "nx")) {
    // 从数据源获取数据
    value = db.get(key);
    // 回写Redis， 并设置过期时间
    redis.setex(key, timeout, value);
    // 删除key_mutex
    redis.delete(mutexKey);
  }
  else {
  //其它线程休息50ms，重写递归获取
  Thread.sleep(50);
  get(key);
  }
}
  return value;
}
```

### 七. BigKey的危害及优化

**1. 什么是BigKey**

在Redis中，一个字符串最大512MB，一个二级数据结构（例如hash、list、set、zset）可以存储大约40亿个(2^32-1)个元素，但实际中如果下面两种情况，我就会认为它是bigkey。

(1). 字符串类型：它的big体现在单个value值很大，一般认为超过10KB就是bigkey。

(2). 非字符串类型：哈希、列表、集合、有序集合，它们的big体现在元素个数太多。

一般来说，string类型控制在**10KB以内**，hash、list、set、zset元素个数**不要超过5000**。反例：一个包含200万个元素的list。非字符串的bigkey，不要使用del删除，使用hscan、sscan、zscan方式渐进式删除，同时要注意防止bigkey过期时间自动删除问题(例如一个200万的zset设置1小时过期，会触发del操作，造成阻塞）

**2. BigKey的危害**

(1). 导致redis阻塞

(2). 网络拥塞

bigkey也就意味着每次获取要产生的网络流量较大，假设一个bigkey为1MB，客户端每秒访问量为1000，那么每秒产生1000MB的流量，对于普通的千兆网卡(按照字节算是128MB/s)的服务器来说简直是灭顶之灾，而且一般服务器会采用单机多实例的方式来部署，也就是说一个bigkey

可能会对其他实例也造成影响，其后果不堪设想。

(3). 过期删除

有个bigkey，它安分守己（只执行简单的命令，例如hget、lpop、zscore等），但它设置了过期时间，当它过期后，会被删除，如果没有使用Redis 4.0的过期异步删除(lazyfree-lazy-expire yes)，就会存在阻塞Redis的可能性。

**3. BigKey的产生**

一般来说，bigkey的产生都是由于程序设计不当，或者对于数据规模预料不清楚造成的，来看几个例子：

(1) 社交类：粉丝列表，如果某些明星或者大v不精心设计下，必是bigkey。

(2) 统计类：例如按天存储某项功能或者网站的用户集合，除非没几个人用，否则必是bigkey。

(3) 缓存类：将数据从数据库load出来序列化放到Redis里，这个方式非常常用，但有两个地方需注意：第一，是不是有必要把所有字段都缓存；第二，有没有相关关联的数据，有的同学为了图方便把相关数据都存一个key下，产生bigkey。

**4. BigKey的优化**

**(1). 拆**

big list： list1、list2、...listN

big hash：可以将数据分段存储，比如一个大的key，假设存了1百万的用户数据，可以拆分成200个key，每个key下面存放5000个用户数据

**(2). 合理采用数据结构**

如果bigkey不可避免，也要思考一下要不要每次把所有元素都取出来(例如有时候仅仅需要hmget，而不是hgetall)，删除也是一样，尽量使用优雅的方式来处理.

反例：

set user:1:name tom 

set user:1:age 19 

set user:1:favor football

推荐hash存对象：

hmset user:1 name tom age 19 favor football

**(3). 控制key的生命周期，redis不是垃圾桶。**

建议使用expire设置过期时间(条件允许可以打散过期时间，防止集中过期)。

------

## 3种常用的缓存读写策略

看到很多小伙伴简历上写了“**熟练使用缓存**”，但是被我问到“**缓存常用的3种读写策略**”的时候却一脸懵逼。

在我看来，造成这个问题的原因是我们在学习 Redis 的时候，可能只是简单了写一些 Demo，并没有去关注缓存的读写策略，或者说压根不知道这回事。

但是，搞懂3种常见的缓存读写策略对于实际工作中使用缓存以及面试中被问到缓存都是非常有帮助的！

下面我会简单介绍一下自己对于这 3 种缓存读写策略的理解。

另外，**这3 种缓存读写策略各有优劣，不存在最佳，需要我们根据具体的业务场景选择更适合的。**

*个人能力有限。如果文章有任何需要补充/完善/修改的地方，欢迎在评论区指出，共同进步！——爱你们的 Guide 哥*

### Cache Aside Pattern（旁路缓存模式）

**Cache Aside Pattern 是我们平时使用比较多的一个缓存读写模式，比较适合读请求比较多的场景。**

Cache Aside Pattern 中服务端需要同时维系 DB 和 cache，并且是以 DB 的结果为准。

下面我们来看一下这个策略模式下的缓存读写步骤。

**写** ：

- 先更新 DB
- 然后直接删除 cache 。

简单画了一张图帮助大家理解写的步骤。

![img](https://cdn.nlark.com/yuque/0/2021/png/2923566/1637774036908-210ac982-0b74-4dd3-aeb3-55785cc7f10f.png)

**读** :

- 从 cache 中读取数据，读取到就直接返回
- cache中读取不到的话，就从 DB 中读取数据返回
- 再把数据放到 cache 中。

简单画了一张图帮助大家理解读的步骤。

![img](https://cdn.jsdelivr.net/gh/houyaogit/Pictures@master/PicGo/1637774036807-e54cfcff-479c-4c66-ac2b-edcfcd07699f.png)

你仅仅了解了上面这些内容的话是远远不够的，我们还要搞懂其中的原理。

比如说面试官很可能会追问：“**在写数据的过程中，可以先删除 cache ，后更新 DB 么？**”

**答案：** 那肯定是不行的！因为这样可能会造成**数据库（DB）和缓存（Cache）数据不一致**的问题。为什么呢？比如说请求1 先写数据A，请求2随后读数据A的话就很有可能产生数据不一致性的问题。这个过程可以简单描述为：

请求1先把cache中的A数据删除 -> 请求2从DB中读取数据->请求1再把DB中的A数据更新。

当你这样回答之后，面试官可能会紧接着就追问：“**在写数据的过程中，先更新DB，后删除cache就没有问题了么？**”

**答案：** 理论上来说还是可能会出现数据不一致性的问题，不过概率非常小，因为缓存的写入速度是比数据库的写入速度快很多！

比如请求1先读数据 A，请求2随后写数据A，并且数据A不在缓存中的话也有可能产生数据不一致性的问题。这个过程可以简单描述为：

请求1从DB读数据A->请求2写更新数据 A 到数据库并把删除cache中的A数据->请求1将数据A写入cache。

现在我们再来分析一下 **Cache Aside Pattern 的缺陷**。

**缺陷1：首次请求数据一定不在 cache 的问题**

解决办法：可以将热点数据可以提前放入cache 中。

**缺陷2：写操作比较频繁的话导致cache中的数据会被频繁被删除，这样会影响缓存命中率 。**

解决办法：

- 数据库和缓存数据强一致场景 ：更新DB的时候同样更新cache，不过我们需要加一个锁/分布式锁来保证更新cache的时候不存在线程安全问题。
- 可以短暂地允许数据库和缓存数据不一致的场景 ：更新DB的时候同样更新cache，但是给缓存加一个比较短的过期时间，这样的话就可以保证即使数据不一致的话影响也比较小。

### Read/Write Through Pattern（读写穿透）

Read/Write Through Pattern 中服务端把 cache 视为主要数据存储，从中读取数据并将数据写入其中。cache 服务负责将此数据读取和写入 DB，从而减轻了应用程序的职责。

这种缓存读写策略小伙伴们应该也发现了在平时在开发过程中非常少见。抛去性能方面的影响，大概率是因为我们经常使用的分布式缓存 Redis 并没有提供 cache 将数据写入DB的功能。

**写（Write Through）：**

- 先查 cache，cache 中不存在，直接更新 DB。
- cache 中存在，则先更新 cache，然后 cache 服务自己更新 DB（**同步更新 cache 和 DB**）。

简单画了一张图帮助大家理解写的步骤。

![img](https://cdn.nlark.com/yuque/0/2021/png/2923566/1637774037117-924c87a8-209f-4f5f-92e7-4827880b5ff7.png)

**读(Read Through)：**

- 从 cache 中读取数据，读取到就直接返回 。
- 读取不到的话，先从 DB 加载，写入到 cache 后返回响应。

简单画了一张图帮助大家理解读的步骤。

![img](https://cdn.nlark.com/yuque/0/2021/png/2923566/1637774037014-36e66ce0-9019-4fad-b8b5-67a5973a5965.png)

Read-Through Pattern 实际只是在 Cache-Aside Pattern 之上进行了封装。在 Cache-Aside Pattern 下，发生读请求的时候，如果 cache 中不存在对应的数据，是由客户端自己负责把数据写入 cache，而 Read Through Pattern 则是 cache 服务自己来写入缓存的，这对客户端是透明的。

和 Cache Aside Pattern 一样， Read-Through Pattern 也有首次请求数据一定不再 cache 的问题，对于热点数据可以提前放入缓存中。

### Write Behind Pattern（异步缓存写入）

Write Behind Pattern 和 Read/Write Through Pattern 很相似，两者都是由 cache 服务来负责 cache 和 DB 的读写。

但是，两个又有很大的不同：**Read/Write Through 是同步更新 cache 和 DB，而 Write Behind Caching 则是只更新缓存，不直接更新 DB，而是改为异步批量的方式来更新 DB。**

很明显，这种方式对数据一致性带来了更大的挑战，比如cache数据可能还没异步更新DB的话，cache服务可能就就挂掉了。

这种策略在我们平时开发过程中也非常非常少见，但是不代表它的应用场景少，比如消息队列中消息的异步写入磁盘、MySQL 的 InnoDB Buffer Pool 机制都用到了这种策略。

Write Behind Pattern 下 DB 的写性能非常高，非常适合一些数据经常变化又对数据一致性要求没那么高的场景，比如浏览量、点赞量。

 ----- 著作权归Guide哥所有。 链接: https://javaguide.cn/database/redis/3-commonly-used-cache-read-and-write-strategies/

### Redis怎么保持缓存与数据库一致性？⭐



**将不一致分为三种情况：**



**1. 数据库有数据缓存没有数据；**



**2. 数据库有数据，缓存也有数据，数据不相等；**



**3. 数据库没有数据，缓存有数据。**



**缓存策略**：大多数人使用的策略，叫做 Cache Aside Pattern。简而言之，就是



**1. 读：首先尝试从缓存读取，读到数据则直接返回；如果读不到，就读数据库，并将数据会写到缓存，并返回。**



**2. 更新： 需要更新数据时，先更新数据库，然后把缓存里对应的数据失效掉（删掉）。**



更新。如果不采取我提到的这种更新方法，你还能想到什么更新方法呢？大概会是：先删除缓存，然后再更新数据库。这么做引发的问题是，如果A,B两个线程同时要更新数据，并且A,B已经都做完了删除缓存这一步，接下来，A先更新了数据库，C线程读取数据，由于缓存没有，则查数据库，并把A更新的数据，写入了缓存，最后B更新数据库。那么缓存和数据库的值就不一致了。另外有人会问，如果采用你提到的方法，为什么最后是把缓存的数据删掉，而不是把更新的数据写到缓存里。这么做引发的问题是，如果A,B两个线程同时做数据更新，A先更新了数据库，B后更新数据库，则此时数据库里存的是B的数据。而更新缓存的时候，是B先更新了缓存，而A后更新了缓存，则缓存里是A的数据。这样缓存和数据库的数据也不一致。按照我提到的这种更新缓存的策略，理论上也是有不一致的风险的，之前在其他的博客文章有看到过，只不过概率很小，我们暂时可以不考虑，后面我们有其他手段来补救。讨论完使用缓存的策略，我们再来看这三种不一致的情况。



**1. 对于第一种，在读数据的时候，会自动把数据库的数据写到缓存，因此不一致自动消除.**



**2. 对于第二种，数据最终变成了不相等，但他们之前在某一个时间点一定是相等的（不管你使用懒加载还是预加载的方式，在缓存加载的那一刻，它一定和数据库一致）。这种不一致，一定是由于你更新数据所引发的。前面我们讲了更新数据的策略，先更新数据库，然后删除缓存。因此，不一致的原因，一定是数据库更新了，但是删除缓存失败了。**



**3. 对于第三种，情况和第二种类似，你把数据库的数据删了，但是删除缓存的时候失败了。**



**因此，最终的结论是，需要解决的不一致，产生的原因是更新数据库成功，但是删除缓存失败。**



解决方案大概有以下几种：



**1. 对删除缓存进行重试，数据的一致性要求越高，我越是重试得快。**



**2. 定期全量更新，简单地说，就是我定期把缓存全部清掉，然后再全量加载。**



**3. 给所有的缓存一个失效期。**



第三种方案可以说是一个大杀器，任何不一致，都可以靠失效期解决，失效期越短，数据一致性越高。但是失效期越短，查数据库就会越频繁。因此失效期应该根据业务来定。



**并发不高的情况：**



**读: 读redis->没有，读mysql->把mysql数据写回redis，有的话直接从redis中取；**



**写: 写mysql->成功，再写redis；**



**并发高的情况：**



**读: 读redis->没有，读mysql->把mysql数据写回redis，有的话直接从redis中取；**



**写：异步话，先写入redis的缓存，就直接返回；定期或特定动作将数据保存到mysql，可以做到多次更新，一次保存；**



无法做到强一致性：（分布式环境下非常容易出现缓存和数据库间数据一致性问题，针对这一点，如果项目对缓存的要求是强一致性的，那么就不要使用缓存。我们只能采取合适的策略来降低缓存和数据库间数据不一致的概率，而无法保证两者间的强一致性。）



### 散列表和跳跃超之类的？？？



### zset跳表的数据结构⭐



增加了向前指针的链表叫作跳表跳表是一个随机化的数据结构，实质就是一种可以进行二分查找的有序链表。跳表在原有的有序链表上面增加了多级索引，通过索引来实现快速查找。跳表不仅能提高搜索性能，同时也可以提高插入和删除操作的性能。



原理：



跳表在原有的有序链表上面增加了多级索引，通过索引来实现快速查找。首先在最高级索引上查找最后一个小于当前查找元素的位置，然后再跳到次高级索引继续查找，直到跳到最底层为止，这时候以及十分接近要查找的元素的位置了(如果查找元素存在的话)。由于根据索引可以一次跳过多个元素，所以跳查找的查找速度也就变快了。



**为什么使用跳跃表**



首先，因为 zset 要支持随机的插入和删除，所以它 **不宜使用数组来实现**，关于排序问题，我们也很容易就想到 **红黑树/ 平衡树** 这样的树形结构，为什么 Redis 不使用这样一些结构呢？



1. **性能考虑：** 在高并发的情况下，树形结构需要执行一些类似于 rebalance 这样的可能涉及整棵树的操作，相对来说跳跃表的变化只涉及局部 *(下面详细说)*；
2. **实现考虑：** 在复杂度与红黑树相同的情况下，跳跃表实现起来更简单，看起来也更加直观；



### redis 分布式锁-超时（Lua脚本延长锁时间）



知道分布式锁吗？有哪些实现方案？谈谈对redis分布式锁的理解，删除key 的时候有什么问题？



redis面试题：



Redis做分布式锁的时候有什么需要注意的问题？



如果redis是单点部署的，会有什么问题？怎么解决单点问题呢？



集群模式下，比如主从模式，有没有什么问题？



简单介绍一下Redlock吧？ 你简历上写redisson， 你谈谈？



Redis分布式锁如何续期？ 看门狗知道吗？



1.  

- 集群环境下，直接使用RedLock 之 Redisson 落地实现
- 并发时候会遇到，被重新抢占的错误

1.  总结： 



synchronzed 单机版ok



分布式，nginx分布式微服务单机锁不行，使用redis分布式锁setnx， 只加锁没有是释放锁，如果出现异常可能无法释放锁，在finally层释放锁



宕机情况也会导致锁没有释放，需要给lockKey设置过期时间



增加过期时间必须要与 setnx同一行的原子性操作



必须规定只能删自己的锁



lua或事务， 集群环境下我们自己写的也不行， 直接使用RedLock之 Redisson 落地实现



## 其他



### Redis是什么



Redis是C语言开发的一个开源的（遵从BSD协议）高性能键值对（key-value）的内存数据库，可以用作数据库、缓存、消息中间件等。它是一种NoSQL（not-only sql，泛指非关系型数据库）的数据库。



Redis作为一个内存数据库。  性能优秀，数据在内存中，读写速度非常快 ， 单进程单线程，是线程安全的，采用IO多路复用机制；



丰富的数据类型，支持字符串（strings）、散列（hashes）、列表（lists）、集合（sets）、有序集合（sorted sets）等；



支持数据持久化。可以将内存中数据保存在磁盘中，重启时加载；



支持 主从复制，哨兵，高可用；



可以用作分布式锁；  可以作为消息中间件使用，支持发布订阅



### Redis 和 memcached 的区别



1. **redis支持更丰富的数据类型（支持更复杂的应用场景）**：Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。memcache支持简单的数据类型，String。
2. **Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而Memecache把数据全部存在内存之中。**
3. **集群模式**：memcached没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 redis 目前是原生支持 cluster 模式的.
4. **Memcached是多线程，非阻塞IO复用的网络模型；Redis使用单线程的多路 IO 复用模型。**



### redis 为什么是单线程的？



因为 cpu 不是 Redis 的瓶颈，Redis 的瓶颈最有可能是机器内存或者网络带宽。既然单线程容易实现，而且 cpu 又不会成为瓶颈，那就顺理成章地采用单线程的方案了。 可以避免多线程上下文切换。



最新的redis6.0后是多线程



### 为什么Redis这么快？⭐



完全基于内存,绝大部分请求是纯粹的内存操作,执行效率高
采用单线程,单线程也能处理高并发请求,想多核也可启动多实例



单线程反而避免了多线程的频繁上下文切换问题，预防了多线程可能产生的竞争问题。



核心是基于非阻塞的 IO 多路复用机制。



### Redis 支持的数据类型有哪些？应用？⭐



1. String字符串:字符串类型是 Redis 最基础的数据结构，首先键都是字符串类型， Value 不仅是 String，也可以是数字。常用在缓存、计数、共享Session、限速等。
2. Hash哈希:在Redis中，哈希类型是指键值本身又是一个键值对结构，哈希可以用来存放用户信息，比如实现购物车。
3. List列表（双向链表）:列表（list）类型是用来存储多个有序的字符串。可以做简单的消息队列的功能。 数据结构：List 就是链表，可以用来当消息队列用。Redis 提供了 List 的 Push 和 Pop 操作，还提供了操作某一段的 API，可以直接查询或者删除某一段的元素。 实现方式：Redis List 的是实现是一个双向链表，既可以支持反向查找和遍历，更方便操作，不过带来了额外的内存开销。
4. Set集合：集合（set）类型也是用来保存多个的字符串元素，集合是通过 hashtable 实现的。 但和列表类型不一样的是，集合中不允许有重复元素，并且集合中的元素是无序的，不能通过索引下标获取元素。利用 Set 的交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。
5. Sorted Set有序集合（跳表实现）：Sorted Set 多了一个权重参数 Score，集合中的元素能够按 Score 进行排列。实现方式：Redis Sorted Set 的内部使用 HashMap 和跳跃表（skipList）来保证数据的存储和有序，HashMap 里放的是成员到 Score 的映射。



### **String 在你们项目怎么用的？**



**常用命令:** set,get,decr,incr,mget 等。



在显示某个人的基本数据的时候，比如名字，粉丝数，关注数，使用 String 保存：



```plain
eg:  user:id:3506728370  
{"id":3506728370,"name":"春晚","fans":12210862,"blogs":6164, "focus":83}
```



设置一个定时刷新的操作，这样用户不需要直接读取数据库。怎么设置？setx key  value，一定时间循环判断key是否失效，到期后再去数据库读取。



### **List 在你们项目怎么用的？**



**常用命令:** lpush,rpush,lpop,rpop,lrange等



1.  朋友圈点赞，要求按照点赞顺序显示点赞好友信息
   如果取消点赞，移除对应好友信息，但是不能使用pop了，怎么办呢？
   解决方案
   lrem key count value **移除指定数据**
   count：移除的数目
   value：具体要移除的内容 
2.  个人用户的关注列表需要按照用户的关注顺序展示。 



### **Set 在你们项目怎么用的？**



每位用户首次使用今日头条时会设置3项爱好的内容，但是后期为了增加用户的活跃度、兴趣点，必须让用户
对其他信息类别逐渐产生兴趣，增加客户留存度，如何实现？



**分析**
系统分析出各个分类的最新或最热点信息条目并组织成set集合
随机挑选其中部分信息
配合用户关注信息分类中的热点信息组织成展示的全信息集合



**解决方案**



-  随机获取集合中指定数量的数据
  srandmember key [count] 
-  随机获取集合中的某个数据并将该数据移出集合
  spop key [count] 



### **zset**项目中使用



在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息（可以理解为按消息维度的消息排行榜）等信息，适合使用 Redis 中的 Sorted Set 结构进行存储。



### zset跳表的数据结构⭐



增加了向前指针的链表叫作跳表跳表是一个随机化的数据结构，实质就是一种可以进行二分查找的有序链表。跳表在原有的有序链表上面增加了多级索引，通过索引来实现快速查找。跳表不仅能提高搜索性能，同时也可以提高插入和删除操作的性能。



原理：



跳表在原有的有序链表上面增加了多级索引，通过索引来实现快速查找。首先在最高级索引上查找最后一个小于当前查找元素的位置，然后再跳到次高级索引继续查找，直到跳到最底层为止，这时候以及十分接近要查找的元素的位置了(如果查找元素存在的话)。由于根据索引可以一次跳过多个元素，所以跳查找的查找速度也就变快了。



**为什么使用跳跃表**



首先，因为 zset 要支持随机的插入和删除，所以它 **不宜使用数组来实现**，关于排序问题，我们也很容易就想到 **红黑树/ 平衡树** 这样的树形结构，为什么 Redis 不使用这样一些结构呢？



1. **性能考虑：** 在高并发的情况下，树形结构需要执行一些类似于 rebalance 这样的可能涉及整棵树的操作，相对来说跳跃表的变化只涉及局部 *(下面详细说)*；
2. **实现考虑：** 在复杂度与红黑树相同的情况下，跳跃表实现起来更简单，看起来也更加直观；



### redis 设置过期时间



Redis中有个设置时间过期的功能，即对存储在 redis 数据库中的值可以设置一个过期时间。作为一个缓存数据库，这是非常实用的。如我们一般项目中的 token 或者一些登录信息，尤其是**短信验证码都是有时间限制的**，按照传统的数据库处理方式，一般都是自己判断过期，这样无疑会严重影响项目性能。



我们 set key 的时候，都可以给一个 expire time，就是过期时间，通过过期时间我们可以指定这个 key 可以存活的时间。



如果假设你设置了一批 key 只能存活1个小时，那么接下来1小时后，redis是怎么对这批key进行删除的？



### 数据过期策略⭐



**定期删除+惰性删除。**



通过名字大概就能猜出这两个删除方式的意思了。



- **定期删除**：redis默认是每隔 100ms 就**随机抽取**一些设置了过期时间的key，检查其是否过期，如果过期就删除。注意这里是随机抽取的。为什么要随机呢？你想一想假如 redis 存了几十万个 key ，每隔100ms就遍历所有的设置过期时间的 key 的话，就会给 CPU 带来很大的负载！
- **惰性删除** ：定期删除可能会导致很多过期 key 到了时间并没有被删除掉。所以就有了惰性删除。假如你的过期 key，靠定期删除没有被删除掉，还停留在内存里，除非你的系统去查一下那个 key，才会被redis给删除掉。



但是仅仅通过设置过期时间还是有问题的。我们想一下：如果定期删除漏掉了很多过期 key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期key堆积在内存里，导致redis内存块耗尽了。怎么解决这个问题呢？ **redis 内存淘汰机制。**



### 数据淘汰机制⭐



当内存到达最大内存限制时进行的数据淘汰策略



1. 新写入操作会报错。（Redis 默认策略）
2. 在键空间中，移除最近最少使用的 Key。（LRU推荐使用）
3. 在键空间中，随机移除某个 Key。
4. 在设置了过期时间的键空间中，移除最近最少使用的 Key。这种情况一般是把 Redis 既当缓存，又做持久化存储的时候才用。
5. 在设置了过期时间的键空间中，随机移除某个 Key。
6. 在设置了过期时间的键空间中，有更早过期时间的 Key 优先移除。



**LRU 算法实现**：1.通过双向链表来实现，新数据插入到链表头部；2.每当缓存命中（即缓存
数据被访问），则将数据移到链表头部；3.当链表满的时候，将链表尾部的数据丢弃。
LinkedHashMap：HashMap 和双向链表合二为一即是 LinkedHashMap。HashMap 是无序
的，LinkedHashMap 通过维护一个额外的双向链表保证了迭代顺序。该迭代顺序可以是插
入顺序（默认），也可以是访问顺序。



### Redis的LRU具体实现：



传统的LRU是使用栈的形式，每次都将最新使用的移入栈顶，但是用栈的形式会导致执行select *的时候大量非热点数据占领头部数据，所以需要改进。Redis每次按key获取一个值的时候，都会更新value中的lru字段为当前秒级别的时间戳。Redis初始的实现算法很简单，随机从dict中取出五个key,淘汰一个lru字段值最小的。在3.0的时候，又改进了一版算法，首先第一次随机选取的key都会放入一个pool中(pool的大小为16),pool中的key是按lru大小顺序排列的。接下来每次随机选取的keylru值必须小于pool中最小的lru才会继续放入，直到将pool放满。放满之后，每次如果有新的key需要放入，需要将pool中lru最大的一个key取出。淘汰的时候，直接从pool中选取一个lru最小的值然后将其淘汰。



### 为什么要用缓存？



用缓存，主要有两个用途：**高性能**、**高并发**。



- 



### redis 怎么实现分布式锁？



Redis 分布式锁其实就是在系统里面占一个“坑”，其他程序也要占“坑”的时候，占用成功了就可以继续执行，失败了就只能放弃或稍后重试。



占坑一般使用 setnx(set if not exists)指令，只允许被一个程序占有，使用完调用 del 释放锁



也可以配合`EXPIRE key seconds`自动释放锁
设置key的生存时间,当key过期时(生存时间为0) ,会被自动删除
风险/ **缺陷** ：原子性没有得到满足，所以不建议。



### 



### 实际项目中使用缓存有遇到什么问题或者会遇到什么问题你知道吗？



缓存和数据库数据一致性问题

### 主从复制



**作用：**
读写分离：master写、slave读，提高服务器的读写负载能力
负载均衡：基于主从结构，配合读写分离，由slave分担master负载，并根据需求的变化，改变slave的数量，通过多个从节点分担数据读取负载，大大提高Redis服务器并发量与数据吞吐量
故障恢复：当master出现问题时，由slave提供服务，实现快速的故障恢复
数据冗余：实现数据热备份，是持久化之外的一种数据冗余方式
高可用基石：基于主从复制，构建哨兵模式与集群，实现Redis的高可用方案



**过程：**



- 从节点执行 **slaveof IP，port** 发送指令
- 主节点响应
- 从节点保存主节点信息（IP，port），建立和主节点的 Socket 连接。
- 从节点发送 Ping 信号，主节点返回 Pong，确定两边能互相通信。
- 连接建立后，主节点将所有数据发送给从节点（数据同步）。
- 主节点把当前的数据同步给从节点后，便完成了复制的建立过程。接下来，主节点就会持续的把写命令发送给从节点，保证主从数据一致性。



**复制/数据同步过程分为两个阶段**



1. 全量复制：
   slave接收到master生成的RDB文件，先清空自身的旧数据，然后执行RDB恢复过程，然后告知master已经恢复完毕。
2. 部分复制（增量复制）
   主节点发送数据给从节点过程中，主节点还会进行一些写操作，这时候的数据存储在复制缓冲区中。master把自己之前创建的复制缓冲区的数据发送到slave，slave接收到aof指令后执行重写操作，恢复数据。



**主从复制会存在以下问题：**



- 一旦主节点宕机，从节点晋升为主节点，同时需要修改应用方的主节点地址，还需要命令所有从节点去复制新的主节点，整个过程需要人工干预。
- 主节点的写能力受到单机的限制。
- 主节点的存储能力受到单机的限制。



**哨兵：**



哨兵(sentinel) 是一个分布式系统，用于对主从结构中的每台服务器进行监控，当出现故障时通过投票机制选择新的master并将所有slave连接到新的master。



**作用：**



**监控**
不断的检查master和slave是否正常运行。
master存活检测、master与slave运行情况检测



**通知（提醒）**
当被监控的服务器出现问题时，向其他（哨兵间，客户端）发送通知。



**自动故障转移**
断开master与slave连接，选取一个slave作为master，将其他slave连接到新的master，并告知客户端新的服务器地址



# 尚硅谷



Redis（代码ing）



Redis传统五大基本类型的应用



redis命令不区分大小写，key区分大小写



——— 帮助文档： help @类型



1. String （字符类型）
2. hash  （散列类型）
3. list  （列表类型）
4. set  （集合类型）
5. Zset  （有序集合类型）
6. Bitmap （位图类型）
7. HyperLogLog（统计）
8. GEO （地理）



### String



set key value



get key



同时设置/获取过个键值



- mset key value [key value ]
- mget key [key]



数值增减



- 递增数字 incr key
- 增加制定的整数 incrby key increment
- 递减数值 decr key
- decrby key increment



获取字符串长度



- strlen key



分布式锁



- setnx key value/ set key value [EX] [PX] [NX|XX]



应用场景



商品编号、订单号采用incr命令生成、 是否喜欢的文章



案件编号（每日更新）



### hash



数据格式： Map<String,Map<Object,object>>



- hset key field value
- Get key field
- Hmset key field value value
- Hmget key field
- 获取所有字段 hgetall key
- 获取某个key内的全部数量 hlen
- 删除一个key hdel
- 应用场景：购物车早起、当前中小厂可用



hash实现的简单购物车：



- 新增商品 hset shopcar ： uid 1024 334488 1
- hset shopcar ： uid 1024 334477 1
- 增加商品数量： hincrby shopcar： uid 1024 334477 1
- 商品总数： hlen shopcar ： uid 1024
- 全部选择： hgetall shopcar ： uid 1024



### list



向列表左边添加元素 ： lpush key value [value …]



向列表右边添加元素  rush key value [value …]



查看列表.  orange key start stop



获取列表中元素个数 llen key



应用场景： 微信文章订阅公众号



### set



添加元素: SADD key member [member ...]



删除元素: SREM key member [member ...]



获取集合中所有元素: SMEMBERS key



判断元素是否在集合中: SISMEMBERS key member



获取集合中元素个数: SCARD key



从集合中随机弹出一个元素，元素不删除: SRANDMEMBER key [数字]



从集合中随机弹出一个元素，出一个删一个: SPOP key [数字]



集合运算



- 集合差集运算A-B: SDIFF key [key ...]
- 集合交集运算AnB: SINTER key [key ...]
- 集合并集运算AuB: SUNION key [key ...]



应用： 抽奖小程序，微信朋友圈点赞，微博好友关注社交关系（共同关注的人。 我关注的人也关注他，大家的共同爱好），QQ内推可能认识的人



### zset



向有序集合中加入一个元素和该元素的分数



添加元素：ZADD score member [score member ...]



按照元素分数从小到大排序，返回索引从start到stop之间所有元素：ZRANGE key start stop [WITHSCORES]



获取元素的分数：ZSCORE key member



删除元素：ZREM key member [member ... ]



获取指定分数范围的元素：ZRANGEYsCORE key min max [WITHSCORES] [LIMIT offset count]



增加某个元素的分数：ZINCRBY key increment member



获取集合中元素的个数：ZCARD key



获得指定分数范围内的元素个数：9zCOUNT key min max



按照排名范围删除元素: ZREMRANGEBYRANK key start stop



获取元素的排名：



- 从小到大 ZRANK key member
- 从大到小 ZREVRANK key member



应用场景：根据商品销售对商品进行排序显示 ， 抖音热搜



- 官网网站首页热搜



定义商品销售排行榜（sorted set 集合），key为goods：sellsort ， 分数为商品销售数量



商品编号1001的销量是9，商品编号1002的销量是15



​	zadd goods：sellsort 9 1001 15 1002



又一个客户又买了两件商品1001， zincrby goods：sellsort 2 1001



求商品销量前10 名 zrange goods：sellsort 0 10



### redis 分布式锁-超时（Lua脚本延长锁时间）



知道分布式锁吗？有哪些实现方案？谈谈对redis分布式锁的理解，删除key 的时候有什么问题？



redis面试题：



Redis做分布式锁的时候有什么需要注意的问题？



如果redis是单点部署的，会有什么问题？怎么解决单点问题呢？



集群模式下，比如主从模式，有没有什么问题？



简单介绍一下Redlock吧？ 你简历上写redisson， 你谈谈？



Redis分布式锁如何续期？ 看门狗知道吗？



1.  单机并发版没有加锁 
2.  

- 解决在单机情况下可以使用synchronized和lock来实现
- 在分布式系统中，因为竞争的线程可能不再同一个节点（同一个JVM中），所以需要一个让所有进程都能访问到的锁来实现，比如redis或者zookeeper来构建；
- 不同进程jvm层面的锁就不管用了，那么可以利用第三方的一个组件，来获取锁，未获取到锁，则阻塞当前想要运行的线程

1.  nginx分布式微服务架构， 上 redis分布式锁 setnx 
2.  出异常的话，可能无法释放锁，必须在代码层面finally 释放锁 
3.  

- lock / unlock 必须同时出现并保证被调用

1.  宕机情况，代码层面没有走到finally，没办法保证解锁，这个key没有被删除，需要加入过期时间限定key 
2.  设置key + 过期时间分开了，必须保证合成一行具备原子性 
3.  张冠李戴删除了别人的锁，只能删自己的锁，不能删别人的锁 
4.  finally块的判断+del删除操作不是原子性， Lua脚本redis可以通过eval命令保证代码执行的原子性 
5.  确保redisLock过期时间大于业务执行时间的问题， redis分布式锁 如何续期？ 
6.  集群CAP对比zookeeper 
7.  

- redis （AP）， redis异步复制造成锁丢失，比如：主节点没来得及把刚刚set进来的这条数据给从节点就挂了，此时如果是集群模式下，就需要使用Redisson来解决
- zookeeper （CP）

1.  综上所述： 
2.  

- 集群环境下，直接使用RedLock 之 Redisson 落地实现
- 并发时候会遇到，被重新抢占的错误

1.  总结： 



synchronzed 单机版ok



分布式，nginx分布式微服务单机锁不行，使用redis分布式锁setnx， 只加锁没有是释放锁，如果出现异常可能无法释放锁，在finally层释放锁



宕机情况也会导致锁没有释放，需要给lockKey设置过期时间



增加过期时间必须要与 setnx同一行的原子性操作



必须规定只能删自己的锁



lua或事务， 集群环境下我们自己写的也不行， 直接使用RedLock之 Redisson 落地实现



### redis 缓存过期淘汰策略（LRU）



LRU是Least Recently Used的缩写，即最近最少使用，是一种常用的页面置换算法



面试题



生产上你们的redis内存设置多少



如何配置修改redis的内存大小



如果内存满了怎么办



redis清理内存的方式？ 定期删除和惰性删除有了解么



redis缓存淘汰策略



redis的LRu了解过吗？ 可否手写一个LRu算法



redis内存满了怎么办（OOM）



-  redis 默认内存多少？在哪里查看？如何设置修改？ 
-  

- 查看redis最大占用内存， 配置文件 maxmemory
- redis默认内存64为操作系统不限制
- 一般生产怎么配置，内存的3/4
- 如何修改redis内存设置， 通过修改文件配置、命令修改
- 查看redis内存使用情况： info memory

-  内存打满了怎么办，没有加过期时间导致数据写满， 引出缓存淘汰机制 



redis缓存淘汰策略



-  redis过期的删除策略 
-  

- 定期删除：对CPU不友好用处理器性能换内存（以时间换空间）
- 惰性删除：对memory不友好，用存储空间换性能（以空间换时间）
- 上面两种都走极端



定期策略是前两种策略的折中



策略有哪些(redis6.0.8版本)



noeviction: 不会驱逐任何key



allkeys-lru: 对所有key使用LRU算法进行删除



volatile-lru: 对所有设置了过期时间的key使用LRU算法进行删除



allkeys-random: 对所有key随机删除



volatile-random: 对所有设置了过期时间的key随机删除



volatile-ttl: 删除马上要过期的key



allkeys-lfu: 对所有key使用LFU算法进行删除



volatile-lfu: 对所有设置了过期时间的key使用LFU算法进行删除



上面总结



2*4得8



2个维度



过期键中筛选



所有键中筛选



4个方面



LRU（最近最少使用）



LFU（频率最少使用）



random



ttl



8个选项



noeviction: 不会驱逐任何key



查看常用策略：



config get maxmemory-policy



config set maxmemory-policy allkeys-lru



redis的LRU了解过吗? 可否手写一个LRU算法



是什么



LRU是Least Recently Used的缩写，即最近最少使用，是一种常用的页面置换算法，



选择最近最久未使用的数据予以淘汰。



算法来源



https://leetcode-cn.com/problems/lru-cache/



设计思想



1 所谓缓存，必须要有读+写两个操作，按照命中率的思路考虑，写操作+读操作时间复杂度都需要为O(1)



2 特性要求分析



2.1 必须有顺序之分，以区分最近使用的和很久没用到的数据排序。



2.2 写和读操作 一次搞定。



2.3 如果容量(坑位)满了要删除最不长用的数据，每次新访问还要把新的数据插入到队头(按照业务你自己设定左右那一边是队头)



​    查找快，插入快，删除快，且还需要先后排序-------->什么样的数据结构满足这个问题?



你是否可以在O(1)时间复杂度内完成这两种操作?



如果一次就可以找到，你觉得什么数据结构最合适??



LRU的算法核心是哈希链表



本质就是HashMap+DoubleLinkedList 时间复杂度是O(1)，哈希表+双向链表的结合体



动画说明



编码手写如何实现LRU



案例01



参考LinkedHashMap



依赖JDK



案例02



不依赖JDK